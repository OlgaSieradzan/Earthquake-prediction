---
title: "Sztuczne sieci neuronowe"
author: "Olga Sieradzan, Justyna Sarkowicz, Weronika Duda, Amelia Madej, Aleksandra Węgrzyn"
date: "2025-01-09"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: true
      smooth_scroll: true
    toc_font: "Arial"
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

```{r}
library(dplyr)
library(cowplot)
library(ggplot2)
library(readr)
library(readxl)
database <- read_csv("msft_us_historical_data.csv")
```

***

# Wprowadzenie 

***

<div style='text-align: justify'>
Umiejętność przewidywania zachowań spółek na giełdzie oraz identyfikacji spadków i wzrostów jest kluczową kompetencją współczesnych algorytmów działających na giełdzie. Szeroka gama narzędzi wspomaga maklerów w podejmowaniu decyzji o środkach, którymi obracają. W tej dziedzinie niezwykle pomocne okazują się sieci neuronowe, które są szeroko wykorzystywane do prognozowania cen na giełdzie.

W ramach badania postanowiono zbadać działanie rekurencyjnych sieci neuronowych (LSTM) na danych dotyczących notowań giełdowych spółki Microsoft od roku 2010. Zbiór treningowy stanowi 80% danych, natomiast działanie modelu jest testowane na ostatnich 20% danych.
</div>

<div style='text-align: justify'>
Modele LSTM charakteryzują się dużą liczbą parametrów, a ich dobór ma istotny wpływ na uzyskane wyniki. W badaniu postanowiono zbadać wpływ 5 różnych parametrów, testując dla każdego z nich 4 różne wartości.

Sprawdzanymi parametrami są; 

* **`Funkcja aktywacji`** - mechanizm, który decyduje o tym, jakie informacje mają zostać podane dalej w sieci, a które mają być zapomniane. 

  *Badane wartości: f.liniowa, f.sigmoidalna, f.ReLU, f.tangensa hiberbolicznego (tanh)*

* **`Rozmiar partii`** - liczba próbek, które są przetwarzane przez model w jednym przebiegu podczas uczenia. Wielkość partii znacząco wpływa na aktualizacje wag w trakcie treningu.

  *Badane wartości: 16, 32, 64, 128*

* **`Liczba wartstw`** - liczba poziomów, przez które przechodzą dane w trakcie prztwarzania. Im więcej takich warstw, tym głębsze są sieci. 

  *Badane wartości: 2, 3, 4, 5*

* **`Liczba neuronów`** - ilość neuronów w pojedynczej warstwie. W neuronie przetwarzane są informacje sieci za pomocą wybranych funkcji aktywacyjnych i przekazywane dalej.

  *Badane wartości: 50, 100, 150, 200*

* **`Optymalizator`** - algorytm działający w celu optymalizacji wag sieci, aby minimalizować błąd predykcji. 

  *Badane wartości: Adam, RMSprop, SGD, Adagrad*
</div>

***

## Dotychczasowe badania nad wykorzystaniem LSTM

***

<div style='text-align: justify'>
W ostatnich latach znaczną popularność zyskały zaawansowane metody sztucznej inteligencji, w tym sieci neuronowe typu Long Short-Term Memory (LSTM). Technologie te znajdują zastosowanie w prognozowaniu przyszłych cen akcji, które są uzależnione od licznych czynników zewnętrznych. W literaturze przedmiotu dostępnych jest wiele badań dotyczących wykorzystania sieci LSTM do predykcji cen akcji, ze szczególnym uwzględnieniem spółki Microsoft.

W artykule zatytułowanym *„Analysis and Forecast of Stock Price Based on LSTM Algorithm”* omówiono wykorzystanie modelu predykcyjnyjnego LSTM do prognozowania cen zamknięcia akcji firmy Microsoft. Wyniki analizy wskazują, iż model LSTM wykazuje wysoka skuteczność prognozowania, uzyskując wartość błędu RMSE o 24,43% niższą w porównaniu do regresji grzbietowej oraz 16,69% niższą w stosunku do klasycznej sieci neuronowej (Liu, 2021).

Podobnie, w publikacji *"Research on Microsoft Stock Price Prediction Based on Various Models"* skupiono się na analizie zastosowania różnych modeli predykcyjnych: regresji liniowej, ARIMA oraz LSTM w prognozowaniu cen akcji firmy Microsoft. Badanie obejmowało dane z okresu od kwietnia 2015 roku do kwietnia 2021 roku. Najlepsze rezultaty uzyskano w przypadku modelu LSTM, który osiągnął znacznie niższą wartość błędu RMSE w porównaniu do regresji liniowej oraz ARIMA. Podkreślono, że zdolność modelu LSTM do uchwycenia skomplikowanych, nieliniowych wzorców w danych czyni go wyjątkowo skutecznym narzędziem w analizie szeregów czasowych (Fu, 2024).

Z kolei w pracy *"Apple, Microsoft, and Amazon stock price prediction based on ARIMA and LSTM"* przeprowadzono analizę porównawczą modeli ARIMA oraz LSTM w kontekście prognozowania cen akcji trzech wiodących spółek technologicznych: Apple, Microsoft oraz Amazon. Wyniki badania wskazują, iż model ARIMA osiąga wyższą dokładność prognoz w porównaniu do modelu LSTM, co zostało ocenione za pomocą wskaźników RMSE oraz $\small R^2$. Zauważono jednak, że ograniczenia badania obejmowały pominięcie zewnętrznych czynników wpływających na ceny akcji oraz uproszczone podejście do optymalizacji modelu LSTM (Xia, 2024).
</div>

***

# Opis danych i metodyki

***

<div style='text-align: justify'>
Do predykcji cen firmy Microsoft wybrano model LSTM (Long Short-Term Memory), ponieważ modele LSTM są wysoce przydatne w modelowaniu danych sekwencyjnych czyli np. szeregów czasowych, którymi są odczyty cen zamknięcia z giełdy.

W celu użycia tego modelu, przeprowadzona została normalizacja danych do zakresu od 0 do 1, za pomocą wzoru:
</div>

$$
X' = \frac{X - \min(X)}{\max(X) - \min(X)}
$$
<div style='text-align: justify'>
Dodatkowo, dane wymagały podziału na sekwencje i odpowiadających im wartości docelowych. Na przykład dla zbioru [1,2,3,4,5] tworzymy dwa podzbiory [1,2,3] ,[2,3,4] oraz odpowiadające im etykiety: [4] i [5]. 
</div>

<div style='text-align: justify'>
Firma Microsoft została wybrana do badania ze względu na popularność spółki (przynależność do wielkiej piątki), i co za tym idzie, dużą ilość publikacji w związku z tą spółką. 
</div>
```{r, echo=FALSE}
split_index <- floor(0.8 * nrow(database))
split_date <- database$Date[split_index]

database %>%
  ggplot()+
  geom_line(aes(x = Date, y = Close)) +
  geom_vline(xintercept = as.numeric(split_date), color = "red", linetype = "dashed", size = 1) +
  theme_light(base_size = 15) +
  labs( title= "Microsoft - notowania na giełdzie", y = "Cena zamknięcia", x = "Data")
```

<div style='text-align: justify'>
Na wykresie można zauważyć dane, na których działano w badaniu. Czerwona linia zaznacza 80% danych, czyli po lewej stronie linii jest zbiór treningowy, natomiast po prawej stronie linii znajduje się zbiór testowy. 

W celu oceny dokładności prognozy i porównania wpływu zmiany parametrów obliczono:

- błąd walidacyjny

- średni błąd kwadratowy (RMSE)

$$
RMSE = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
$$

- R-kwadrat 

$$
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
$$

Im wartość $RMSE$ jest bliższa 0, tym lepsza i dokładniejsza jest prognoza modelu.

Natomiast $R^2$ oznacza jaki procent $y$ został wyjaśnionych przez model. Im wartośc bliższa 1 (100%), tym lepszy model, ponieważ wyjaśnia większy procent danych. 

W tabelkach podano średnie $RMSE$ i $R^2$ ze wszystkich prób dla danych parametrów.

</div>

***

# Analiza wpływu różnych parametrów

***

<div style='text-align: justify'>
Łącznie przeprowadzono 100 prognozowań, 5 razy dla każdego zestawu parametrów. Badano wpływ 5 różnych parametrów. W sprawozdaniu pokazywany będzie zestaw wykresów dla jednej z 5 prób przeprowadzonych dla wszystkich parametrów w celu zaoszczędzenia miejsca i długości sprawozdania. Dostęp do wykresów dla wszytskich prób przeprowadzonych w ramach badania jest w folderze 'plots', dołączonym do sprawozdania.
</div>

***

```{r, echo=FALSE, include=FALSE}
neurons <- read_excel("results.xlsx", sheet = "neurons")
optimizer <- read_excel("results.xlsx", sheet = "optimizer")
activation <- read_excel("results.xlsx", sheet = "activation")
batch_size <- read_excel("results.xlsx", sheet = "batch_size")
layers <- read_excel("results.xlsx", sheet = "layers")
```


## Funkcja aktywacji

***

<div style='text-align: justify'>
Na poniższych wykresach zaprezentowano wyniki dla 4 badanych funkcji aktywacji.
</div>

<br>
```{r fig.align="center"}
x <- seq(-10, 10, length.out = 500)
data <- data.frame(
  x = rep(x, 4),
  y = c(
    x,                                        # h(x) = x
    ifelse(x >= 0, x, 0),                    # h(x) = {x, x >= 0; 0, x < 0}
    1 / (1 + exp(-x)),                   # h(x) = 1 / (1 + e^(-x)) 
    2 / (1 + exp(-2 * x)) - 1                # h(x) = 2 / (1 + e^(-2x)) - 1
  ),
  function_name = factor(rep(
    c("f. liniowa", 
      "f. ReLU", 
      "f. sigmoidalna", 
      "f. tanh"), 
    each = length(x)
  ))
)

# Tworzenie wykresu
ggplot(data, aes(x = x, y = y, color = function_name)) +
  geom_line(size = 1.2) +
  labs(
    title = "Wykres funkcji aktywacyjnych h(x)",
    x = "x",
    y = "h(x)",
    color = "Funkcje"
  ) +
  theme_light(base_size = 14) +
  ylim(-1.5, 1.5)
```


Pozostałe parametry pozostają stałe:

* liczba neuronów = 20

* optymalizator = Adam

* rozmiar partii = 16

* liczba warstw  = 3

<br>

***

<br>
**Funkcja liniowa**

$$h(x) = x$$




```{r}
knitr::include_graphics("activation_linear_rep_3.png")
```

***

<br>
**Funkcja ReLU**

$$
h(x) = 
\begin{cases} 
x, & x \geq 0 \\ 
0, & x \leq 0 
\end{cases}
$$

```{r}
knitr::include_graphics("activation_relu_rep_2.png")
```

***

<br>
**Funkcja sigmoidalna**

$$
h(x) = \frac{1}{(1+e^{-x})}-1
$$

```{r}
knitr::include_graphics("activation_sigmoid_rep_4.png")
```

***

<br>
**Funkcja tangens hiperboliczny**

$$
h(x) = \frac{2}{(1+e^{-2x})}-1
$$

```{r}
knitr::include_graphics("activation_tanh_rep_4.png")
```

**Przeciętny błąd prognozy**
<div style='text-align: justify'>
Blędy zostały policzone jako średnia dla wszytskich 5 prób
</div>
```{r, echo=FALSE}
act <- activation %>%
  group_by(Value) %>%
  summarise(
    RMSE = mean(RMSE),
    R2 = mean(R2)
  ) %>%
  as.data.frame() 

colnames(act) <- c("f.aktywacyjna", "RMSE", "R2")

act
```


<div style='text-align: justify'>
Najniższy błąd walidacji wyszedł w przypadku funkcji liniowej (~ 0.0015) oraz funkcji ReLU (~ 0.002), chociaż warto wspomnieć, że w przypadku dwóch prób, które można znaleźć w folderze plots, funkcja ReLU zaprognozowała same zera. Natomiast jej wartość $R^2$ i RMSE wskazują na całkowite niedopasowanie modelu. Wysokie wartości RMSE i ujemne $R^2$ mogą wskazywać na możliwe przeszacowanie modelu lub niedoszacowanie. Natomiast zdecydowanie lepiej wypada funkcja liniowa, która ma najniższy błąd walidacyjny i RMSE w porównaniu do reszty. $R^2$ ~0.9 wskazuje na dobre wyjaśnienie danych za pomocą modelu. Jednak błąd pomimo tego, że jest naniższy w porównaniu do pozostałych to nadal jest dość wysoki.

Słabym dopasowaniem cechuje się funkcja sigmoidalna, gdzie błąd walidacji sięgnął 0.03, a $R^2$ wynosi zalediwe ~0.0.4. W wynikach dla tej funkcji można zauważyć zdecydowane niedoszacowanie w momencie, w którym spółka Microsoft osiągała wyższe ceny na giełdzie. Podobnie jest w przypadku użycia funkcji tanh.  
</div>

***

## Rozmiar partii

***

<div style='text-align: justify'>
Na poniższych wykresach zaprezentowano wyniki dla zwiekszającej się ilości próbek w partii.

Pozostałe parametry pozostają stałe:

* liczba neuronów = 20

* optymalizator = Adam

* funkcja aktywacji = f.liniowa

* liczba warstw  = 3
</div>

<br>

***

<br>
**16 próbek**

```{r}
knitr::include_graphics("batch_size_16_rep_1.png")
```

***

<br>
**32 próbki**

```{r}
knitr::include_graphics("batch_size_32_rep_1.png")
```

***

<br>
**64 próbki**

```{r}
knitr::include_graphics("batch_size_64_rep_1.png")
```

***

<br>
**128 próbek**

```{r}
knitr::include_graphics("batch_size_128_rep_1.png")
```

```{r, echo=FALSE}
ba <- batch_size %>%
  group_by(Value) %>%
  summarise(
    RMSE = mean(RMSE),
    R2 = mean(R2)
  ) %>%
  as.data.frame() 
colnames(ba) <- c("Rozmiar partii", "RMSE", "R2")
ba
```

<div style='text-align: justify'>
Dla pierwszych trzech badanych rozmiarów partii różnica nie wydaje się znacząca. Błędy walidacji są bardzo podobne i oscylują wokół 0.003. Natomiast zwiększenie rozmiaru partii do 128 próbek, wprowadza pogorszenie się wyników i zwiekszenie błędu walidacji. Możemy to również zauważyć, po wartościach RMSE i $R^2$. W przypadku $R^2$ widać nieznaczący spadek wraz ze wzrostem rozmiaru partii, natomiast dla RMSE zaobserwowano lekki wzrost wartości wraz ze wzrostem rozmiaru partii.  Nie są to co prawda duże różnice, ale są zauważalne. Dopasowanie modeli nie jest najgorsze, $R^2$ ~ 0.8 pokazuje, że duża część danych została wyjaśniona przez model.
</div>

***

## Liczba warstw

***

<div style='text-align: justify'>
Poniżej zaprezentowano wykresy dla zwiększającej się ilości warstw w zbudowanym modelu. 

Pozostałe parametry pozostają stałe:

* liczba neuronów = 20

* optymalizator = Adam

* funkcja aktywacji = f.liniowa

* rozmiar partii = 16
</div>

<br>

***

<br>
**2 warstwy**

```{r}
knitr::include_graphics("layers_2_rep_1.png")
```

***

<br>
**3 warstwy**

```{r}
knitr::include_graphics("layers_3_rep_0.png")
```

***

<br>
**4 warstwy**

```{r}
knitr::include_graphics("layers_4_rep_2.png")
```

***

<br>
**5 warstw**

```{r}
knitr::include_graphics("layers_5_rep_1.png")
```

```{r, echo=FALSE}
lay <- layers %>%
  group_by(value) %>%
  summarise(
    RMSE = mean(rmse),
    R2 = mean(R2)
  ) %>%
  as.data.frame() 

colnames(lay) <- c("Liczba warstw", "RMSE", "R2")
lay
```

<div style='text-align: justify'>
Na wykresach można zauważyć zależność, że im więcej warstw, tym predykcja minimalnie gorsza. Widać to również po $R^2$ i RMSE. Wraz ze wzrostem liczby warstw maleje $R^2$ i rośnie RMSE w znaczącym stopniu. Już dla 5 warstw wyjaśniane jest tylko 44% danych przez model, a RMSE wynosi 28.885. Natomiast dla 2 warstw wyjaśniane jest aż 95% danych i RMSE to tylko 8.42.

</div>

***

## Liczba neuronów

***

<div style='text-align: justify'>
Poniżej zaprezentowano wykresy dla zwiększającej się liczby neuronów w warstwach w zbudowanym modelu. 

Pozostałe parametry pozostają stałe:

* liczba warstw = 3

* optymalizator = Adam

* funkcja aktywacji = f.liniowa

* rozmiar partii = 16
</div>

<br>

***

<br>
**50 neuronów**

```{r}
knitr::include_graphics("neurons_50_rep_0.png")
```

***

<br>
**100 neuronów**

```{r}
knitr::include_graphics("neurons_100_rep_1.png")
```

***

<br>
**150 neuronów**

```{r}
knitr::include_graphics("neurons_150_rep_4.png")
```

***

<br>
**200 neuronów**

```{r}
knitr::include_graphics("neurons_200_rep_3.png")
```

```{r, echo=FALSE}
ne <- neurons %>%
  group_by(Value) %>%
  summarise(
    RMSE = mean(RMSE),
    R2 = mean(R2)
  ) %>%
  as.data.frame() 

colnames(ne) <- c("Liczba neuronów", "RMSE", "R2")
ne
```

<div style='text-align: justify'>
Błąd walidacyjny w większości przypadków waha się wokół 0.001. Dla liczby neuronów = 200, jest on jednak niższy. We wszystkich sytuacjach występują duże wahania błędu walidacyjnego. 

Wraz ze wzrostem liczby neuronów w modelu rośnie stopień dopasowania modelu do danych, co znajduje odzwierciedlenie w wysokim $R^2$, wyjaśniającym ponad 90% zmienności danych.

RMSE zmniejsza się wraz ze wzrostem liczby neuronów, co oznacza lepsze dopasowanie modelu. Na początku spadek RMSE jest dość znaczący, jednak przy większej liczbie neuronów różnice stają się mniej zauważalne. Mimo to, wartość RMSE pozostaje dość wysoka, wynosząc blisko 10 dla wszystkich analizowanych parametrów.
</div>

***

## Optymalizator

***

<div style='text-align: justify'>
Poniżej zaprezentowano wykresy dla różnych optymalizatorów w zbudowanym modelu. 

Pozostałe parametry pozostają stałe:

* liczba warstw = 3

* liczba neuronów = 20

* funkcja aktywacji = f.liniowa

* rozmiar partii = 16
</div>

<br>

***

<br>
**Adagrad**

<div style='text-align: justify'>
Adagrad automatycznie dostosowuje krok optymalizacji dla każdego parametru w oparciu o historię gradientów. Wagi, które często mają duże gradienty, otrzymują mniejsze kroki optymalizacji. Parametry rzadko aktualizowane mają większe kroki optymalizacji.
</div>

```{r}
knitr::include_graphics("optimizer_Adagrad_rep_0.png")
```

<div style='text-align: justify'>
Dla optymalizatora Adagrad widzimy, że błąd walidacyjny zmierza do błędu trenowania. Wykres błędu różni się zdecydowanie od  wykresów w innych przypadkach. Nie mamy tutaj takich wahań, ale dla początkowych epok wartości błędu są dość wysokie. Prognoza dość mocno się różni od rzeczywistych wartości.
</div>

***

<br>
**Adam**

<div style='text-align: justify'>
Adam utrzymuje zbiór wykładniczo malejących średnich poprzednich gradientów i kwadratowych gradientów. Oblicza pierwszy i drugi moment gradientów, które są odpowiednio oszacowaniami średniej i niecentrowanej wariancji gradientów. Te momenty są następnie wykorzystywane do aktualizacji parametrów modelu.
</div>

```{r}
knitr::include_graphics("optimizer_Adam_rep_4.png")
```

<div style='text-align: justify'>
Dla optymalizatora Adam błąd już zaczyna się wahać. Jednak na przestrzeni wszystkich epok błąd jest bardzo niski. Powyżej 20 epok jest on niższy niż 0.001. Tutaj prognoza jest praktycznie identyczna jak rzeczywiste wartości, stąd też takie niskie wartości błędu.
</div>

***

<br>
**RMSprop**

<div style='text-align: justify'>
RMSprop to ulepszenie SGD, które dynamicznie dostosowuje krok optymalizacji w zależności od gradientów. Skaluje krok optymalizacji w zależności od wielkości gradientu – mniejsze kroki dla dużych gradientów i większe dla małych gradientów.
</div>

```{r}
knitr::include_graphics("optimizer_RMSprop_rep_2.png")
```

<div style='text-align: justify'>
Dla optymalizatora RMSprop również mamy duże wahania błędu. Jednak wartości są bardzo niskie, zwłaszcza w porównaniu do optymalizatora Adagrad. Natomiast błąd nie schodzi tutaj tak nisko jak w przypadku opt. Adam. Tutaj dopasowanie prognozy też jest bardzo dobre.
</div>

***

<br>
**SGD**

<div style='text-align: justify'>
SGD aktualizuje parametry w małych partiach danych treningowych, dzięki czemu jest wydajny obliczeniowo. Dostosowuje parametry w kierunku najbardziej stromego spadku funkcji straty, stopniowo zbiegając się w kierunku minimum.
</div>

```{r}
knitr::include_graphics("optimizer_SGD_rep_1.png")
```

Dla optymalizatora SGD ponownie jest sytuacja taka, jak dla opt. Adagrad. Wartości błędu na przestrzeni epok są bardzo wysokie. Maleje zdecydowanie wolniej niż w innych przypadkach. Wypada on tutaj najgorzej. Możemy to też zobaczyć po prognozie cen, że uzyskane wyniki znacząco się różnią od rzeczywistych. 

```{r, echo=FALSE}
op <- optimizer %>%
  group_by(Value) %>%
  summarise(
    RMSE = mean(RMSE),
    R2 = mean(R2)
  ) %>%
  as.data.frame()
colnames(op) <- c("Optymalizator", "RMSE", "R2")

op
```

<div style='text-align: justify'>

Adam wykazuje najlepsze wyniki pod względem RMSE i $R^2$. Niskie RMSE wskazuje na dobre dopasowanie modelu do danych, a wysokie $R^2$ sugeruje, że model wyjaśnia prawie całą zmienność danych. Dla RMSprop wartości RMSE są wyższe niż w przypadku Adama, $R^2$ jest nadal wysokie, co oznacza, że model jest dość dobrze dopasowany do danych. W przypadku Adagrad zarówno RMSE i $R^2$ zdecydowanie gorzej wypadają w porównaniu do 2 poprzednich optymalizatorów. Natomiast najgorzej wypada SGD. RMSE jest bardzo wysokie, a $R^2$ ujemne, co oznacza, że model jest całkowicie niedopasowany do danych. Potwierdzają to również prognozy, które są dalekie od rzeczywistych.

Najlepiej zdecydowanie wypada optymalizator Adam. Daje on najniższe wartości błędu i prognoza jest najlepiej dopasowana do rzeczywistych wartości. Najgorzej natomiast wypada optymalizator SGD. W odróżnieniu od pozostałych nie wykorzystuje on adaptacyjnego tempa uczenia.
</div>

***

# Podsumowanie

***

<div style='text-align: justify'>
Przeprowadzona analiza umożliwiła zbadanie wpływu kluczowych parametrów modelu LSTM na skuteczność predykcji cen akcji spółki Microsoft. Badanie dotyczyło wpływu wielkości następujących parametrów: funkcji aktywacji, rozmiaru partii, liczby warstw, liczby neuronów oraz wyboru optymalizatora. Uzyskane wyniki wskazały na występowanie istotnej zależności pomiędzy doborem parametrów a jakością prognoz, co zostało szczegółowo omówione poniżej:

* **`Funkcja aktywacji`**: funkcje liniowa oraz ReLU okazały się najbardziej skuteczna w kontekście prognozowania, wykazując mniejsze błędy walidacji w porównaniu z innymi funkcjami. Pozostałe z analizowanych funkcji tj. funkcja tangensa hiperbolicznego oraz funkcja sigmoidalna cechują się słabym dopasowaniem.

* **`Rozmiar partii`**: w przypadku rozmiarów partii odpowiednio: 16, 32 oraz 64 wystepowały zbliżone wartości błędów walidacji. Zwiększenie rozmiaru partii do 128 próbek spowodowało pogorszenie uzyskanych wyników. 

* **`Liczba warstw`**: zwiększenie liczby warstw prowadziło do pogorszenia predykcji i występowania większych błędów walidacji.

* **`Liczba neuronów`**: we wszystkich analizowanych przypadkach występują znaczące wahania błędów walidacyjnych, jednakże w przypadku liczby neuronów wynoszącej 200 można zauważyć niższe wartości tego błędu.

* **`Optymalizator`**: optymalizator Adam wykazał się najniższymi wartościami błędów walidacyjnych oraz najwyższym stopniem dopasowania wartości do danych rzeczywistych. Najgorzsze wyniki osiągnął optymalizator SGD, gdyż w porównaniu do pozostałych nie stosuje adaptacyjnego tempa uczenia.
</div>

***

## Porównanie wyników

***

<div style='text-align: justify'>
W artykule *„Apple, Microsoft, and Amazon stock price prediction based on ARIMA and LSTM”* dokonano porównania modeli **ARIMA** oraz **LSTM** w kontekście prognozowania. 
ARIMA to jedna z najpopularniejszych metod modelowania szeregów czasowych. Skrót ARIMA opisuje jej trzy kluczowe komponenty:

- AR (Autoregressive): Model autoregresyjny opisuje zależność wartości szeregu czasowego od jego wcześniejszych wartości. Parametr p określa liczbę opóźnionych wartości branych pod uwagę.

- I (Integrated): Część "zintegrowana" oznacza różnicowanie szeregu czasowego w celu usunięcia trendu lub uzyskania stacjonarności. Parametr d określa liczbę takich różnicowań.

- MA (Moving Average): Model średniej ruchomej opisuje zależność wartości szeregu od błędów z poprzednich kroków. Parametr  q określa liczbę takich błędów branych pod uwagę.

Dla spółki Microsoft wykorzystano dane z 1 września 2021 do 29 września 2023. Zatem ilość danych była zdecydowanie mniejsza niż w naszym badaniu. Zasotowano również inny podział danych: 60% to zbiór treningowy, 20% zbiór walidaycjny i ostatnie 20% to zbiór testowy.

```{r, echo=FALSE}
methods <- c("LSTM", "ARIMA", "LSTM")
source <- c("Artykuł", "Artykuł", "Nasz wynik")
RMSE <- c(5.0984, 1.8729, 6.558908)
R2 <- c(0.7806, 0.9715, 0.9712344)
	
results <- data.frame(
  Metoda = methods,
  Źródło = source,
  RMSE = RMSE,
  R2 = R2
)
results
```

W tabelce zestawiono RMSE i $R^2$ uzyskane w artykule (skrót art.) oraz nasz najlepszy wynik, który 
następujących wartości parametrów: 

* liczba warstw = 3

* liczba neuronów = 20

* funkcja aktywacji = f.liniowa

* rozmiar partii = 16

* optymalizator = Adam

$R^2$ wypada bardzo podobnie dla nasze LSTM i ARIMY. Natomiast ARIMA osiągnęła znacznie niższy błąd (1.8729) w porównaniu do naszego LSTM (6.5589), co wskazuje, że ARIMA lepiej przewidziała dane w przypadku tych danych. Wyniki LSTM z artykułu mają nieco niższy błąd RMSE, ale zdecydowanie niższy $R^2$. Parametry przyjęte w artykule dla LSTM różniły sie znacząco stąd też mogły wyjść rozbieżne wyniki.

Arima wykazuje lepszą dokładnością w prognozowaniu cen akcji ze względu na wskaźniki RMSE i $R^2$. LSTM jest bardziej wymagające pod kątem dobrania odpowiednich parametrów i ich wartości. 

</div>

*** 

# Bibliografia 

***

1. Fu, Y. (2024). *Research on Microsoft Stock Price Prediction Based on Various Models*. Proceedings of the 1st International Conference on Data Science and Engineering, 11–16

2. Liu, Y. (2021). *Analysis and forecast of stock price based on LSTM algorithm*. 2021 IEEE International Conference on Computer Science, Electronic Information Engineering and Intelligent Control Technology (CEI), Fuzhou, China, 76-79

3. Xia, X. (2024). *Apple, Microsoft, and Amazon stock price prediction based on ARIMA and LSTM*. Applied and Computational Engineering, 53(1), 181–189

4. Wall, K. (2022). *Negative R2: Where did you go wrong*. Towards Data Science, https://towardsdatascience.com/negative-r2-where-did-you-go-wrong-9d4f2aa84cfb






