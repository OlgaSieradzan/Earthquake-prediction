---
title: "Sprawozdanie"
author: "Olga Sieradzan, Justyna Sarkowicz, Weronika Duda, Amelia Madej, Aleksandra Węgrzyn"
date: "2025-01-09"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: 
      collapsed: true
      smooth_scroll: true
    toc_font: "Arial"
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```


```{r}
library(dplyr)
library(cowplot)
library(ggplot2)
library(readr)
database <- read_csv("msft_us_historical_data.csv")

```


# Wprowadzenie 

<div style='text-align: justify'>
Umiejętność przewidywania zachowań spółek na giełdzie oraz identyfikacji spadków i wzrostów jest kluczową kompetencją współczesnych algorytmów działających na giełdzie. Szeroka gama narzędzi wspomaga maklerów w podejmowaniu decyzji o środkach, którymi obracają. W tej dziedzinie niezwykle pomocne okazują się sieci neuronowe, które są szeroko wykorzystywane do prognozowania cen na giełdzie.

<div style='text-align: justify'>
W ramach badania postanowiono zbadać działanie rekurencyjnych sieci neuronowych (LSTM) na danych dotyczących notowań giełdowych spółki Microsoft od roku 2010. Zbiór treningowy stanowi 80% danych, natomiast działanie modelu jest testowane na ostatnich 20% danych.

<div style='text-align: justify'>
Modele LSTM zależą od dużej liczby parametrów, a ich dobór ma istotny wpływ na wyniki. W badaniu postanowiono zbadać wpływ 5 różnych parametrów, testując przy każdym z nich 4 różne wartości.

Sprawdzanymi parametrami są; 

* **Funkcja aktywacji** - mechanizm który decyduje o tym jakie informacje mają zostać podane dalej w sieci, a które mają być zapomniane. 

  *Badane wartości: f.liniowa, f.sigmondalna, f.relu, f.tangens hiberboliczny(tanh)*

* **Rozmiar partii** - liczba próbek, które są przetważane przez model w jednym przebiegu podczas uczenia. Wielkość partii znacząco wpływa na aktualizacje wag w trakcie treningu.

  *Badane wartości: 16, 32, 64, 128*

* **Liczba wartstw** - liczba poziomów przez które przechodzą dane w trakcie prztwarzania. Im wiecej takich warstw tym głębsze są sieci. 

  *Badane wartości: 2, 3, 4, 5*

* **Liczba neuronów** - ilość neuronów w pojedyńczej warstwie. W neuronie przetważane są informacje sieci za pomocą wybranych funkcji aktywacyjnych i przekazywane dalej.

  *Badane wartości: 50, 100, 150, 200*

* **Optymalizator** - algorytm działający w celu optymalizacji wag sieci aby minimaliozwać błąd predykcji. 

  *Badane wartości: Adam, RMSprop, SGD, Adagrad*

# Opis danych i metodyki

Do predyckji cen firmy Microsoft wbrano model LSTM (Long Short-Term Memory), ponieważ modele LSTM są wysoce przydatne w modelowaniu danych sekwencyjnych czyli np. szeregów czasowych, którym są odczyty cen zamknięcia z giełdy.

W celu użycia tego modelu, przeprowadzona została normalizacja danych do zakresu od 0 do 1, za pomocą wzoru 
$$
X' = \frac{X - \min(X)}{\max(X) - \min(X)}
$$

Dodatkowo, dane potrzebowały podziału na sekwencje i odpowiadających im wartości docelowych. Na przykład dla zbioru [1,2,3,4,5], tworzymy dwa podzbiory [1,2,3] ,[2,3,4] oraz odpowiadające im etykiety, [4] i [5]. 


<div style='text-align: justify'>
Firma Microsoft została wybrana do badania ze względu na popularność spółki (przynależnośc do wielkiej piątki), i co za tym idzie, dużą ilość publikacji w związku z tą spółką. 

```{r}
split_index <- floor(0.8 * nrow(database))
split_date <- database$Date[split_index]

database %>%
  ggplot()+
  geom_line(aes(x = Date, y = Close)) +
  geom_vline(xintercept = as.numeric(split_date), color = "red", linetype = "dashed", size = 1) + 
  
  theme_light(base_size = 15) +
  
  labs( title= "Microsoft - notowania na giełdzie", y = "Cena zamknięcia", x = "Data")
```

<div style='text-align: justify'>
Na wykresie można zauważyć dane na których działano w badaniu. Czerwona linia zaznacza 80% danych, czyli po lewej stronie lini jest zbiór treningowy, natomiast po prawej stronie lini widac zbiór testowy.

# Wyniki

<div style='text-align: justify'>
Łącznie przeprowadzono 100 prognozowań, 5 razy dla każdego zestawu parametrów. Badano wpływ 5 różnych parametrów. W sprawozdaniu pokazywany będzie zestaw wykresów dla jednen z 5 prób przeprowadzonych dla wszytskich parametrów, w celu zaoszczędzenia miejsca i długości sprawozdania. Dostęp do wykresów dla wszytskich prób przeprowadzonych w ramach badania jest w folderze 'plots', dołączonym do sprawozdania.

## Funkcja aktywacyjna 

<div style='text-align: justify'>
Na poniższych wykresach zaprezentowano wyniki dla 4 badanych funkcji aktywacyjnych. 

Pozostałe parametry pozostają stałe:

* liczba neuronów = 20

* optymalizator = Adam

* rozmiar partii = 16

* liczba warstw  = 3

**Funkcja liniowa**

```{r}
knitr::include_graphics("activation_linear_rep_3.png")
```


**Funkcja relu**

```{r}
knitr::include_graphics("activation_relu_rep_2.png")
```


**Funkcja sigmoindalna**

```{r}
knitr::include_graphics("activation_sigmoid_rep_4.png")
```

**Funkcja tangenshiperboliczny**

```{r}
knitr::include_graphics("activation_tanh_rep_4.png")
```


<div style='text-align: justify'>
Najniższy błąd walidacji wyszedł w przypadku funkcji liniowej oraz funkcji relu (~ 0.002), chociaż warto wspomnieć że w przypadku dwóch prób, które mozna znaleśc w folderze plots, funckja relu zaprognozowała same zera. 

<div style='text-align: justify'>
Słabym dopasowaniem cechuje się funkcja sigmoindalna, gdzie błąd walidacji sięgnał 0.03. W wynikach dla tej funkcji można zauważyć zdecydowne niedoszacowanie w momencie w którym spółka microsoft osiągała wyższe ceny na giełdzie. Podobnie jest w przypadku użycia funkcji tanh. 

## Rozmiar partii

<div style='text-align: justify'>
Na ponizszych wykresach, zaprezentowano wyniki dla zwiekszającej się ilości próbek w partii.

Pozostałe parametry pozostają stałe:

* liczba neuronów = 20

* optymalizator = Adam

* funkcja aktywacji = f.liniowa

* liczba warstw  = 3

**16 próbek**

```{r}
knitr::include_graphics("batch_size_16_rep_1.png")
```


**32 próbki**

```{r}
knitr::include_graphics("batch_size_32_rep_1.png")
```

**64 próbki**

```{r}
knitr::include_graphics("batch_size_64_rep_1.png")
```

**128 próbek**

```{r}
knitr::include_graphics("batch_size_128_rep_1.png")
```

<div style='text-align: justify'>
Dla pierwszych trzech badanych rozmiarów partii, różnica nie wydaje się znacząca. Błędy walidacji są bardzo podobne i oscylują dookoła 0.003. 

<div style='text-align: justify'>
Natomiast zwiekszenie romiaru partii do 128 próbek, wprowadza pogorszenie się wyników i zwiekszenie błędu walidacji. 

## Liczba wartsw

<div style='text-align: justify'>
Na poniższych wykresach zaprzentowano wykresy dla zwiekszającej się ilości wartw w zbudowanym modelu. 

Pozostałe parametry pozostają stałe:

* liczba neuronów = 20

* optymalizator = Adam

* funkcja aktywacji = f.liniowa

* rozmiar partii = 16

**2 warstwy**

```{r}
knitr::include_graphics("layers_2_rep_4.png")
```

**3 warstwy**

```{r}
knitr::include_graphics("layers_3_rep_0.png")
```

**4 warstwy**

```{r}
knitr::include_graphics("layers_4_rep_2.png")
```


**5 warstw**

```{r}
knitr::include_graphics("layers_5_rep_4.png")
```

<div style='text-align: justify'>
Na wykresach można zauważyć zależność , że im wiecej wartstw tym predykcja minimalnie gorsza. Badacze nie spodziewali sie takiej zależności.  













