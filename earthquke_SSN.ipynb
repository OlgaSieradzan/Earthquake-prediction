{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Earthquake prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plik ./msft_us_historical_data.csv już istnieje\n",
      "         Date     Open     High      Low    Close        Volume\n",
      "0  2010-01-04  24.0854  24.4389  24.0358  24.3178  4.886916e+07\n",
      "1  2010-01-05  24.2542  24.4389  24.0765  24.3267  6.331174e+07\n",
      "2  2010-01-06  24.2642  24.4230  23.9852  24.1758  7.403254e+07\n",
      "3  2010-01-07  24.0537  24.1232  23.7221  23.9257  6.434577e+07\n",
      "4  2010-01-08  23.7837  24.2642  23.7608  24.0934  6.515561e+07\n"
     ]
    }
   ],
   "source": [
    "# Ścieżka do pliku CSV w repozytorium\n",
    "csv_path = './msft_us_historical_data.csv'\n",
    "\n",
    "# Sprawdzenie, czy plik istnieje\n",
    "if not os.path.exists(csv_path):\n",
    "    # URL do pobrania danych historycznych dla MSFT.US\n",
    "    url = 'https://stooq.com/q/d/l/?s=msft.us&i=d&d1=20100101&d2=20240101'\n",
    "    \n",
    "    # Pobieranie danych\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Sprawdzenie, czy żądanie się powiodło\n",
    "    if response.status_code == 200:\n",
    "        # Zapisanie danych do pliku CSV w repozytorium\n",
    "        with open(csv_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        \n",
    "        print(f'Dane zostały pobrane i zapisane do {csv_path}')\n",
    "    else:\n",
    "        print(f'Błąd podczas pobierania danych: {response.status_code}')\n",
    "else:\n",
    "    print(f'Plik {csv_path} już istnieje')\n",
    "\n",
    "# Wczytanie danych do DataFrame\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Wyświetlenie pierwszych kilku wierszy\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MinMaxScaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Normalizacja danych\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m \u001b[43mMinMaxScaler\u001b[49m(feature_range\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m      6\u001b[0m scaled_data \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(data)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Tworzenie sekwencji danych\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MinMaxScaler' is not defined"
     ]
    }
   ],
   "source": [
    "# Wybór kolumny 'Close' do predykcji\n",
    "data = df['Close'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalizacja danych\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "# Tworzenie sekwencji danych\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        sequences.append(data[i:i + seq_length])\n",
    "        labels.append(data[i + seq_length])\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "seq_length = 60\n",
    "X, y = create_sequences(scaled_data, seq_length)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date      Time  Latitude  Longitude        Type  Depth  Depth Error  \\\n",
      "0  01/02/1965  13:44:18    19.246    145.616  Earthquake  131.6          NaN   \n",
      "1  01/04/1965  11:29:49     1.863    127.352  Earthquake   80.0          NaN   \n",
      "2  01/05/1965  18:05:58   -20.579   -173.972  Earthquake   20.0          NaN   \n",
      "3  01/08/1965  18:49:43   -59.076    -23.557  Earthquake   15.0          NaN   \n",
      "4  01/09/1965  13:32:50    11.938    126.427  Earthquake   15.0          NaN   \n",
      "\n",
      "   Depth Seismic Stations  Magnitude Magnitude Type  ...  \\\n",
      "0                     NaN        6.0             MW  ...   \n",
      "1                     NaN        5.8             MW  ...   \n",
      "2                     NaN        6.2             MW  ...   \n",
      "3                     NaN        5.8             MW  ...   \n",
      "4                     NaN        5.8             MW  ...   \n",
      "\n",
      "   Magnitude Seismic Stations  Azimuthal Gap  Horizontal Distance  \\\n",
      "0                         NaN            NaN                  NaN   \n",
      "1                         NaN            NaN                  NaN   \n",
      "2                         NaN            NaN                  NaN   \n",
      "3                         NaN            NaN                  NaN   \n",
      "4                         NaN            NaN                  NaN   \n",
      "\n",
      "   Horizontal Error  Root Mean Square            ID  Source Location Source  \\\n",
      "0               NaN               NaN  ISCGEM860706  ISCGEM          ISCGEM   \n",
      "1               NaN               NaN  ISCGEM860737  ISCGEM          ISCGEM   \n",
      "2               NaN               NaN  ISCGEM860762  ISCGEM          ISCGEM   \n",
      "3               NaN               NaN  ISCGEM860856  ISCGEM          ISCGEM   \n",
      "4               NaN               NaN  ISCGEM860890  ISCGEM          ISCGEM   \n",
      "\n",
      "  Magnitude Source     Status  \n",
      "0           ISCGEM  Automatic  \n",
      "1           ISCGEM  Automatic  \n",
      "2           ISCGEM  Automatic  \n",
      "3           ISCGEM  Automatic  \n",
      "4           ISCGEM  Automatic  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Invalid Dates:\n",
      "                           Date                      Time  Latitude  \\\n",
      "7511   1985-04-28T02:53:41.530Z  1985-04-28T02:53:41.530Z   -32.998   \n",
      "20649  2011-03-13T02:23:34.520Z  2011-03-13T02:23:34.520Z    36.344   \n",
      "\n",
      "       Longitude        Type  Depth  Depth Error  Depth Seismic Stations  \\\n",
      "7511     -71.766  Earthquake   33.0          NaN                     NaN   \n",
      "20649    142.344  Earthquake   10.1         13.9                   289.0   \n",
      "\n",
      "       Magnitude Magnitude Type  ...  Magnitude Seismic Stations  \\\n",
      "7511         5.6             MW  ...                         NaN   \n",
      "20649        5.8            MWC  ...                         NaN   \n",
      "\n",
      "       Azimuthal Gap  Horizontal Distance  Horizontal Error  Root Mean Square  \\\n",
      "7511             NaN                  NaN               NaN              1.30   \n",
      "20649           32.3                  NaN               NaN              1.06   \n",
      "\n",
      "               ID Source Location Source Magnitude Source    Status  \n",
      "7511   USP0002E81     US              US              HRV  Reviewed  \n",
      "20649  USP000HWQP     US              US             GCMT  Reviewed  \n",
      "\n",
      "[2 rows x 21 columns]\n",
      "Invalid Times:\n",
      "                           Date                      Time  Latitude  \\\n",
      "7511   1985-04-28T02:53:41.530Z  1985-04-28T02:53:41.530Z   -32.998   \n",
      "20649  2011-03-13T02:23:34.520Z  2011-03-13T02:23:34.520Z    36.344   \n",
      "\n",
      "       Longitude        Type  Depth  Depth Error  Depth Seismic Stations  \\\n",
      "7511     -71.766  Earthquake   33.0          NaN                     NaN   \n",
      "20649    142.344  Earthquake   10.1         13.9                   289.0   \n",
      "\n",
      "       Magnitude Magnitude Type  ...  Magnitude Seismic Stations  \\\n",
      "7511         5.6             MW  ...                         NaN   \n",
      "20649        5.8            MWC  ...                         NaN   \n",
      "\n",
      "       Azimuthal Gap  Horizontal Distance  Horizontal Error  Root Mean Square  \\\n",
      "7511             NaN                  NaN               NaN              1.30   \n",
      "20649           32.3                  NaN               NaN              1.06   \n",
      "\n",
      "               ID Source Location Source Magnitude Source    Status  \n",
      "7511   USP0002E81     US              US              HRV  Reviewed  \n",
      "20649  USP000HWQP     US              US             GCMT  Reviewed  \n",
      "\n",
      "[2 rows x 21 columns]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m invalid_dates_after \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mmatch(date_pattern, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Convert invalid 'Time' entries to datetime and extract only the time component\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mmatch(time_pattern, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mM:\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mS:\u001b[39m\u001b[38;5;132;01m%2f\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m invalid_times_after \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mmatch(time_pattern, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Display invalid dates\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\strings\\accessor.py:137\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\strings\\accessor.py:1376\u001b[0m, in \u001b[0;36mStringMethods.match\u001b[1;34m(self, pat, case, flags, na)\u001b[0m\n\u001b[0;32m   1338\u001b[0m \u001b[38;5;129m@forbid_nonstring_types\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbytes\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmatch\u001b[39m(\u001b[38;5;28mself\u001b[39m, pat: \u001b[38;5;28mstr\u001b[39m, case: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, flags: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1340\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1341\u001b[0m \u001b[38;5;124;03m    Determine if each string starts with a match of a regular expression.\u001b[39;00m\n\u001b[0;32m   1342\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1374\u001b[0m \u001b[38;5;124;03m    dtype: bool\u001b[39;00m\n\u001b[0;32m   1375\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1376\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_result(result, fill_value\u001b[38;5;241m=\u001b[39mna, returns_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\strings\\object_array.py:222\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_match\u001b[1;34m(self, pat, case, flags, na)\u001b[0m\n\u001b[0;32m    219\u001b[0m regex \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pat, flags\u001b[38;5;241m=\u001b[39mflags)\n\u001b[0;32m    221\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: regex\u001b[38;5;241m.\u001b[39mmatch(x) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\strings\\object_array.py:78\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_map\u001b[1;34m(self, f, na_value, dtype, convert)\u001b[0m\n\u001b[0;32m     76\u001b[0m map_convert \u001b[38;5;241m=\u001b[39m convert \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(mask)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 78\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_convert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mAttributeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;66;03m# Reraise the exception if callable `f` got wrong number of args.\u001b[39;00m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;66;03m# The user may want to be warned by this, instead of getting NaN\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     p_err \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     83\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m((takes)|(missing)) (?(2)from \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ to )?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+ \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(?(3)required )positional arguments?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     85\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2895\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mlib.pyx:2932\u001b[0m, in \u001b[0;36mpandas._libs.lib._map_infer_mask\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\core\\strings\\object_array.py:221\u001b[0m, in \u001b[0;36mObjectStringArrayMixin._str_match.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    217\u001b[0m     flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mIGNORECASE\n\u001b[0;32m    219\u001b[0m regex \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39mcompile(pat, flags\u001b[38;5;241m=\u001b[39mflags)\n\u001b[1;32m--> 221\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: regex\u001b[38;5;241m.\u001b[39mmatch(x) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_str_map(f, na_value\u001b[38;5;241m=\u001b[39mna, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mbool\u001b[39m))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load and Preprocess Data\n",
    "# Assuming you have a CSV file with earthquake data\n",
    "df = pd.read_csv('./dataset/database.csv')\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "# print(data.head())\n",
    "\n",
    "# Check NA values\n",
    "# print(df.isna().sum())\n",
    "\n",
    "print(df.head())\n",
    " \n",
    "# print(df.dtypes)\n",
    "# Filter rows where 'Date' does not match the pattern\n",
    "date_pattern = r'^\\d{2}/\\d{2}/\\d{4}$'\n",
    "invalid_dates = df[~df['Date'].str.match(date_pattern, na=False)]\n",
    "time_pattern = r'^\\d{2}:\\d{2}:\\d{2}$'\n",
    "invalid_times = df[~df['Time'].str.match(time_pattern, na=False)]\n",
    "\n",
    "\n",
    "# Display invalid dates\n",
    "print(\"Invalid Dates:\")\n",
    "print(invalid_dates)\n",
    "\n",
    "print(\"Invalid Times:\")\n",
    "print(invalid_times)\n",
    "\n",
    "df.loc[~df['Date'].str.match(date_pattern, na=False), 'Date'] = pd.to_datetime(df.loc[~df['Date'].str.match(date_pattern, na=False), 'Date'], errors='coerce').dt.strftime('%d/%m/%Y')\n",
    "invalid_dates_after = df[~df['Date'].str.match(date_pattern, na=False)]\n",
    "\n",
    "# Convert invalid 'Time' entries to datetime and extract only the time component\n",
    "df.loc[~df['Time'].str.match(time_pattern, na=False), 'Time'] = pd.to_datetime(df.loc[~df['Time'].str.match(time_pattern, na=False), 'Time'], errors='coerce').dt.strftime('%M:%S:%2f')\n",
    "invalid_times_after = df[~df['Time'].str.match(time_pattern, na=False)]\n",
    "\n",
    "\n",
    "# Display invalid dates\n",
    "print(\"Invalid Dates:\")\n",
    "print(invalid_dates_after)\n",
    "\n",
    "print(\"Invalid Times:\")\n",
    "print(invalid_times_after)\n",
    "\n",
    "# Convert 'Date' column to datetime, coercing errors\n",
    "# df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# print(df.head())\n",
    "# print(df['Date'].isna().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
